<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//en">

<!--Converted with LaTeX2HTML 2020 (Released January 1, 2020) -->
<HTML lang="en">
<HEAD>
<TITLE>CSCI 662 Fall 2020 course page</TITLE>
<META NAME="description" CONTENT="CSCI 662 Fall 2020 course page">
<META NAME="keywords" CONTENT="main">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="viewport" CONTENT="width=device-width, initial-scale=1.0">
<META NAME="Generator" CONTENT="LaTeX2HTML v2020">

<LINK REL="STYLESHEET" HREF="main.css">

</HEAD>

<BODY >
<H1 class="CENTER">CSCI 662 Fall 2020 course page</H1>
<DIV>

<STRONG>Jonathan May</STRONG>
</DIV>
<BR>
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Website</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360><kbd><A ID="tex2html1"
  HREF="https://www.isi.edu/~jonmay/cs662_fa20_web/">https://www.isi.edu/~jonmay/cs662_fa20_web/</A></kbd></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Lectures</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360><kbd><A ID="tex2html2"
  HREF="https://usc.zoom.us/j/92532775397">https://usc.zoom.us/j/92532775397</A></kbd> (password on piazza) , Mondays and Wednesdays 10:00&ndash;11:50 am</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Instructor &amp; office hours</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>Jonathan May, Online, Mondays and Wednesdays 9:00&ndash;10:00 am or by appointment (same room as lectures)</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>TAs &amp; Office hours</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>Mozhdeh Gheini, Tuesdays and Thursdays, 1:00&ndash;2:00 pm, Online</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>Meryem M'Hamdi, Mondays and Wednesdays, 4:00&ndash;5:00 pm, Online</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Textbook</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360><B>Required:</B> Natural Language Processing - Eisenstein<A ID="tex2html3"
  HREF="#foot106"><SUP>1</SUP></A></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360><B>Required:</B> Selected papers from NLP literature, see (evolving) schedule</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360><I>Optional:</I> Introduction to Deep Learning - Charniak <A ID="tex2html6"
  HREF="#foot107"><SUP>2</SUP></A></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360><I>Optional:</I> Speech and Language Processing 3rd edition -Jurafsky, Martin  <A ID="tex2html9"
  HREF="#foot108"><SUP>3</SUP></A></TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Grading</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>10 %: In-class participation</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>10 %: Posted questions before each in-class selected paper presentation</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>10 %: In-class selected paper presentation</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>30 %: Three Homeworks (10% each)</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>40 %: Project, comprising proposal (10%), final conference-quality paper (15%), and 15-minute in-class presentation (15%) (may be done in small groups). Final report is due December 7, 2020, 10:00 AM PST</TD>
</TR>
<TR><TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Contact us</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=360>On Piazza or in class/office hours. Please do not email (unless notified otherwise).</TD>
</TR>
</TABLE>

<P>
Topics (subject to change per instructor/class whim) (will not be presented in this order):

<P>

<UL>
<LI>Linguistic Stack (graphemes/phones - words - syntax - semantics - pragmatics - discourse)
</LI>
<LI>Tools:
     
<UL>
<LI>Corpora, Corpus statistics, Data cleaning and munging
</LI>
<LI>Annotation and crowdwork
</LI>
<LI>Evaluation
</LI>
<LI>Models/approaches: rule-based, automata/grammars, perceptron, logistic regression, neural network models
</LI>
<LI>Effective written and oral communication
     
</LI>
</UL>
</LI>
<LI>Components/Tasks/Subtasks:
     
<UL>
<LI>Language Models
</LI>
<LI>Syntax: POS tags, constituency tree, dependency tree, parsing
</LI>
<LI>Semantics: lexical, formal, inference tasks
</LI>
<LI>Information Extraction: Named Entities, Relations, Events
</LI>
<LI>Generation: Machine Translation, Summarization, Dialogue, Creative Generation
    
</LI>
</UL>
</LI>
</UL>

<P>
<TABLE CELLPADDING=3 BORDER="1">
<TR><TD ALIGN="LEFT">date</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>material</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>reading</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>presentation</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Other</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>TA attending</TD>
</TR>
<TR><TD ALIGN="LEFT">8/24</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>intro, applications</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 1 (not mandatory)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem &amp; Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">8/26</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>end of intro, probability basics</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein Appendix A, Goldwater probability tutorial <A ID="tex2html11"
  HREF="#foot110"><SUP>4</SUP></A></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>project assignment out (due 9/9)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">
<P>

<P>
8/31</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>probability, ethics, naive bayes</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 2, Nathan Schneider's unix notes<A ID="tex2html13"
  HREF="#foot111"><SUP>5</SUP></A>, Unix for poets<A ID="tex2html15"
  HREF="#foot112"><SUP>6</SUP></A>, sculpting text<A ID="tex2html17"
  HREF="#foot113"><SUP>7</SUP></A></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>The Social Impact of Natural Language Processing<A ID="tex2html19"
  HREF="#foot114"><SUP>8</SUP></A> <B>Presenter: Jon</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>-</TD>
</TR>
<TR><TD ALIGN="LEFT">9/2</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Perceptron, Logistic Regression</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 3, Charniak 1.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Thumbs up? Sentiment Classification using Machine Learning Techniques<A ID="tex2html21"
  HREF="#foot115"><SUP>9</SUP></A> <B>Presenter: Zekun</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>HW1 out (due 9/30)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">9/7</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>LABOR DAY NO CLASS</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
</TR>
<TR><TD ALIGN="LEFT">9/9</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Nonlinear classifiers, backpropagation, gradient descent</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 7</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Fast Semantic Extraction Using a Novel Neural Network Architecture<A ID="tex2html23"
  HREF="#foot116"><SUP>10</SUP></A> <B>Presenter: Tooraj</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>project proposal due</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">9/14</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>POS tags, HMMs</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 9,2, 10.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Part-of-Speech Tagging for Twitter: Annotation, Features, and Experiments<A ID="tex2html25"
  HREF="#foot117"><SUP>11</SUP></A> <B>Presenter: Negar</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">9/16</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>cky, constituencies, treebank</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 11</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Building a Large Annotated Corpus of English<A ID="tex2html27"
  HREF="#foot118"><SUP>12</SUP></A> <B>Presenters: Ani, Sabyasachee</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">9/21</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>viterbi cky, restructuring, dependencies, shift-reduce</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 4.5.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>A Fast and Accurate Dependency Parser using Neural Networks<A ID="tex2html29"
  HREF="#foot119"><SUP>13</SUP></A> <B>Presenter: Shweta</B>.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">9/23</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>arc-eager, evaluation, human annotation</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 13, 14.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>An Empirical Investigation of Statistical Significance in NLP <A ID="tex2html31"
  HREF="#foot120"><SUP>14</SUP></A> <B>Presenter: Nikolaos</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>HW2 out (due 10/21)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">9/28</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>NO CLASS</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
</TR>
<TR><TD ALIGN="LEFT">9/30</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>mechanical turk, semantics: word sense, propbank, amr, distributional</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 7</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Linguistic Regularities in Continuous Space Word Representations<A ID="tex2html33"
  HREF="#foot121"><SUP>15</SUP></A>. <B>Presenter: Hongkuan</B> The word analogy testing caveat<A ID="tex2html35"
  HREF="#foot122"><SUP>16</SUP></A> <B>Presenter: Jihoon</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>HW1 due</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">10/5</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>language models: ngram, feed-forward, recurrent  Machine Translation history, evaluation</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 18.1, 18.2</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Bleu: a Method for Automatic Evaluation of Machine Translation<A ID="tex2html37"
  HREF="#foot123"><SUP>17</SUP></A> <B>Presenter: Paras</B> Towards a Literary Machine Translation: The Role of Referential Cohesion<A ID="tex2html39"
  HREF="#foot124"><SUP>18</SUP></A> <B>Presenter: Katy</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">10/7</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Statistical, Neural Machine Translation, summarization, generation</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 18.3, 19.1, 19.2</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Effective Approaches to Attention-based Neural Machine Translation<A ID="tex2html41"
  HREF="#foot125"><SUP>19</SUP></A> <B>Presenter: Xiou</B> Neural Machine Translation by Jointly Learning to Align and Translate<A ID="tex2html43"
  HREF="#foot126"><SUP>20</SUP></A> <B>Presenter: Soumya</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Revised proposals due (no late days)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">10/12</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Transformers</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Attention is all you need <A ID="tex2html45"
  HREF="#foot127"><SUP>21</SUP></A>, Illustrated Transformer <A ID="tex2html47"
  HREF="#foot128"><SUP>22</SUP></A></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144><P>
Six Challenges for Neural Machine Translation<A ID="tex2html49"
  HREF="#foot129"><SUP>23</SUP></A> <B>Presenter: Yuchen</B>.
Get To The Point: Summarization with Pointer-Generator Networks<A ID="tex2html51"
  HREF="#foot130"><SUP>24</SUP></A> <B>Presenter: Qi</B>.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">10/14</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Large Contextualized Language Models (ElMo, BERT, GPT-N, etc.)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Illustrated BERT, ElMo, and co.<A ID="tex2html53"
  HREF="#foot131"><SUP>25</SUP></A></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Universal Neural Machine Translation for Extremely Low Resource Languages <A ID="tex2html55"
  HREF="#foot132"><SUP>26</SUP></A> <B>Presenter: Amirhesam</B>. Defending Against Neural Fake News <A ID="tex2html57"
  HREF="#foot133"><SUP>27</SUP></A> <B>Presenter: Yizhou</B>.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>HW3 out (due 11/11)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">10/19</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Guest Lecture (Xuezhe Ma)</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Language Models are Unsupervised Multitask Learners <A ID="tex2html59"
  HREF="#foot134"><SUP>28</SUP></A> <B>Presenter: I-Hung</B>.  Language Models are Few-Shot Learners<A ID="tex2html61"
  HREF="#foot135"><SUP>29</SUP></A> <B>Presenters: Yufei, Wenxuan</B>.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">10/21</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Information Extraction: Entity/Relation, CRF</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 17.1, 17.2</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>25 years of IE<A ID="tex2html63"
  HREF="#foot136"><SUP>30</SUP></A> <B>Presenter: Justin</B>.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>HW2 Due</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">10/26</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Information Extraction: Events, Zero-shot</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 17.3</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Events are Not Simple: Identity, Non-Identity, and Quasi-Identity<A ID="tex2html65"
  HREF="#foot137"><SUP>31</SUP></A> <B>Presenter: Basel</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">10/28</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Blade Runner NLP/Bertology</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding<A ID="tex2html67"
  HREF="#foot138"><SUP>32</SUP></A> <B>Presenter: Prateek</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">11/2</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Text Games and Reinforcement Learning</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives<A ID="tex2html69"
  HREF="#foot139"><SUP>33</SUP></A> <B>Presenter: Shuai</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">11/4</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Dialogue</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Eisenstein 19.3.</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>A Diversity-Promoting Objective Function for Neural Conversation Models<A ID="tex2html71"
  HREF="#foot140"><SUP>34</SUP></A> <B>Presenter: Peifeng</B> Personalizing Dialogue Agents: I have a dog, do you have pets too?<A ID="tex2html73"
  HREF="#foot141"><SUP>35</SUP></A> <B>Presenter: Akshat</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">
<P>

<P>
11/9</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Power and Ethics</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data<A ID="tex2html75"
  HREF="#foot142"><SUP>36</SUP></A> <B>Presenter: Ani</B> Energy and Policy Considerations for Deep Learning in NLP <A ID="tex2html77"
  HREF="#foot143"><SUP>37</SUP></A> <B>Presenter: Ali A.</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">
<P>
11/11</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>How to write a paper</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>Neubig slides on Piazza</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>On Measuring Social Biases in Sentence Encoders <A ID="tex2html79"
  HREF="#foot144"><SUP>38</SUP></A> <B>Presenter: Katy</B></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>HW3 Due</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem</TD>
</TR>
<TR><TD ALIGN="LEFT">
<P>

<P>
11/16</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Presentations</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem &amp; Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">11/18</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Presentations</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem &amp; Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">
<P>
11/23</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>Presentations</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>Meryem &amp; Mozhdeh</TD>
</TR>
<TR><TD ALIGN="LEFT">
<P></TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=216>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=144>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
<TD ALIGN="LEFT" VALIGN="TOP" WIDTH=72>&nbsp;</TD>
</TR>
</TABLE>

<P>
<BR><HR><H4>Footnotes</H4>
<DL>
<DT><A ID="foot106">... Eisenstein</A><A
 HREF="main.html#tex2html3"><SUP>1</SUP></A></DT>
<DD><kbd><A ID="tex2html4"
  HREF="https://mitpress.mit.edu/books/introduction-natural-language-processing">https://mitpress.mit.edu/books/introduction-natural-language-processing</A></kbd> or free version <kbd><A ID="tex2html5"
  HREF="https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf">https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf</A></kbd>

</DD>
<DT><A ID="foot107">... Charniak</A><A
 HREF="main.html#tex2html6"><SUP>2</SUP></A></DT>
<DD><kbd><A ID="tex2html7"
  HREF="https://mitpress.mit.edu/books/introduction-deep-learning">https://mitpress.mit.edu/books/introduction-deep-learning</A></kbd> (first three chapters at <kbd><A ID="tex2html8"
  HREF="https://cs.brown.edu/courses/csci1460/assets/files/deep-learning.pdf">https://cs.brown.edu/courses/csci1460/assets/files/deep-learning.pdf</A></kbd>)

</DD>
<DT><A ID="foot108">... Martin</A><A
 HREF="main.html#tex2html9"><SUP>3</SUP></A></DT>
<DD><kbd><A ID="tex2html10"
  HREF="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</A></kbd>

</DD>
<DT><A ID="foot110">... tutorial</A><A
 HREF="main.html#tex2html11"><SUP>4</SUP></A></DT>
<DD><kbd><A ID="tex2html12"
  HREF="http://homepages.inf.ed.ac.uk/sgwater/teaching/general/probability.pdf">http://homepages.inf.ed.ac.uk/sgwater/teaching/general/probability.pdf</A></kbd>

</DD>
<DT><A ID="foot111">... notes</A><A
 HREF="main.html#tex2html13"><SUP>5</SUP></A></DT>
<DD><kbd><A ID="tex2html14"
  HREF="https://github.com/nschneid/unix-text-commands">https://github.com/nschneid/unix-text-commands</A></kbd>

</DD>
<DT><A ID="foot112">... poets</A><A
 HREF="main.html#tex2html15"><SUP>6</SUP></A></DT>
<DD><kbd><A ID="tex2html16"
  HREF="https://www.cs.upc.edu/~padro/Unixforpoets.pdf">https://www.cs.upc.edu/~padro/Unixforpoets.pdf</A></kbd>

</DD>
<DT><A ID="foot113">... text</A><A
 HREF="main.html#tex2html17"><SUP>7</SUP></A></DT>
<DD><kbd><A ID="tex2html18"
  HREF="http://matt.might.net/articles/sculpting-text/">http://matt.might.net/articles/sculpting-text/</A></kbd>

</DD>
<DT><A ID="foot114">... Processing</A><A
 HREF="main.html#tex2html19"><SUP>8</SUP></A></DT>
<DD><kbd><A ID="tex2html20"
  HREF="https://www.aclweb.org/anthology/P16-2096/">https://www.aclweb.org/anthology/P16-2096/</A></kbd>

</DD>
<DT><A ID="foot115">... Techniques</A><A
 HREF="main.html#tex2html21"><SUP>9</SUP></A></DT>
<DD><kbd><A ID="tex2html22"
  HREF="https://www.aclweb.org/anthology/W02-1011/">https://www.aclweb.org/anthology/W02-1011/</A></kbd>

</DD>
<DT><A ID="foot116">... Architecture</A><A
 HREF="main.html#tex2html23"><SUP>10</SUP></A></DT>
<DD><kbd><A ID="tex2html24"
  HREF="https://www.aclweb.org/anthology/P07-1071/">https://www.aclweb.org/anthology/P07-1071/</A></kbd>

</DD>
<DT><A ID="foot117">... Experiments</A><A
 HREF="main.html#tex2html25"><SUP>11</SUP></A></DT>
<DD><kbd><A ID="tex2html26"
  HREF="https://www.aclweb.org/anthology/P11-2008/">https://www.aclweb.org/anthology/P11-2008/</A></kbd>

</DD>
<DT><A ID="foot118">... English</A><A
 HREF="main.html#tex2html27"><SUP>12</SUP></A></DT>
<DD><kbd><A ID="tex2html28"
  HREF="https://www.aclweb.org/anthology/J93-2004.pdf">https://www.aclweb.org/anthology/J93-2004.pdf</A></kbd>

</DD>
<DT><A ID="foot119">... Networks</A><A
 HREF="main.html#tex2html29"><SUP>13</SUP></A></DT>
<DD><kbd><A ID="tex2html30"
  HREF="https://www.aclweb.org/anthology/D14-1082/">https://www.aclweb.org/anthology/D14-1082/</A></kbd>

</DD>
<DT><A ID="foot120">... NLP</A><A
 HREF="main.html#tex2html31"><SUP>14</SUP></A></DT>
<DD><kbd><A ID="tex2html32"
  HREF="https://www.aclweb.org/anthology/D12-1091/">https://www.aclweb.org/anthology/D12-1091/</A></kbd>

</DD>
<DT><A ID="foot121">... Representations</A><A
 HREF="main.html#tex2html33"><SUP>15</SUP></A></DT>
<DD><kbd><A ID="tex2html34"
  HREF="https://www.aclweb.org/anthology/N13-1090.pdf">https://www.aclweb.org/anthology/N13-1090.pdf</A></kbd>

</DD>
<DT><A ID="foot122">... caveat</A><A
 HREF="main.html#tex2html35"><SUP>16</SUP></A></DT>
<DD><kbd><A ID="tex2html36"
  HREF="https://www.aclweb.org/anthology/N18-2039.pdf">https://www.aclweb.org/anthology/N18-2039.pdf</A></kbd>

</DD>
<DT><A ID="foot123">... Translation</A><A
 HREF="main.html#tex2html37"><SUP>17</SUP></A></DT>
<DD><kbd><A ID="tex2html38"
  HREF="https://www.aclweb.org/anthology/P02-1040">https://www.aclweb.org/anthology/P02-1040</A></kbd>

</DD>
<DT><A ID="foot124">... Cohesion</A><A
 HREF="main.html#tex2html39"><SUP>18</SUP></A></DT>
<DD><kbd><A ID="tex2html40"
  HREF="https://www.aclweb.org/anthology/W12-2503/">https://www.aclweb.org/anthology/W12-2503/</A></kbd>

</DD>
<DT><A ID="foot125">... Translation</A><A
 HREF="main.html#tex2html41"><SUP>19</SUP></A></DT>
<DD><kbd><A ID="tex2html42"
  HREF="https://www.aclweb.org/anthology/D15-1166/">https://www.aclweb.org/anthology/D15-1166/</A></kbd>

</DD>
<DT><A ID="foot126">... Translate</A><A
 HREF="main.html#tex2html43"><SUP>20</SUP></A></DT>
<DD><kbd><A ID="tex2html44"
  HREF="https://arxiv.org/abs/1409.0473">https://arxiv.org/abs/1409.0473</A></kbd>

</DD>
<DT><A ID="foot127">... need</A><A
 HREF="main.html#tex2html45"><SUP>21</SUP></A></DT>
<DD><kbd><A ID="tex2html46"
  HREF="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</A></kbd>

</DD>
<DT><A ID="foot128">... Transformer</A><A
 HREF="main.html#tex2html47"><SUP>22</SUP></A></DT>
<DD><kbd><A ID="tex2html48"
  HREF="http://jalammar.github.io/illustrated-transformer/">http://jalammar.github.io/illustrated-transformer/</A></kbd>

</DD>
<DT><A ID="foot129">... Translation</A><A
 HREF="main.html#tex2html49"><SUP>23</SUP></A></DT>
<DD><kbd><A ID="tex2html50"
  HREF="https://www.aclweb.org/anthology/W17-3204/">https://www.aclweb.org/anthology/W17-3204/</A></kbd>

</DD>
<DT><A ID="foot130">... Networks</A><A
 HREF="main.html#tex2html51"><SUP>24</SUP></A></DT>
<DD><kbd><A ID="tex2html52"
  HREF="https://www.aclweb.org/anthology/P17-1099/">https://www.aclweb.org/anthology/P17-1099/</A></kbd>

</DD>
<DT><A ID="foot131">... co.</A><A
 HREF="main.html#tex2html53"><SUP>25</SUP></A></DT>
<DD><kbd><A ID="tex2html54"
  HREF="http://jalammar.github.io/illustrated-bert/">http://jalammar.github.io/illustrated-bert/</A></kbd>

</DD>
<DT><A ID="foot132">... Languages</A><A
 HREF="main.html#tex2html55"><SUP>26</SUP></A></DT>
<DD><kbd><A ID="tex2html56"
  HREF="https://www.aclweb.org/anthology/N18-1032/">https://www.aclweb.org/anthology/N18-1032/</A></kbd>

</DD>
<DT><A ID="foot133">... News</A><A
 HREF="main.html#tex2html57"><SUP>27</SUP></A></DT>
<DD><kbd><A ID="tex2html58"
  HREF="https://papers.nips.cc/paper/9106-defending-against-neural-fake-news.pdf">https://papers.nips.cc/paper/9106-defending-against-neural-fake-news.pdf</A></kbd>

</DD>
<DT><A ID="foot134">... Learners</A><A
 HREF="main.html#tex2html59"><SUP>28</SUP></A></DT>
<DD><kbd><A ID="tex2html60"
  HREF="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf</A></kbd>

</DD>
<DT><A ID="foot135">... Learners</A><A
 HREF="main.html#tex2html61"><SUP>29</SUP></A></DT>
<DD><kbd><A ID="tex2html62"
  HREF="https://arxiv.org/abs/2005.14165">https://arxiv.org/abs/2005.14165</A></kbd>

</DD>
<DT><A ID="foot136">... IE</A><A
 HREF="main.html#tex2html63"><SUP>30</SUP></A></DT>
<DD>in piazza or <kbd><A ID="tex2html64"
  HREF="https://www.cambridge.org/core/journals/natural-language-engineering/article/twentyfive-years-of-information-extraction/0E5BB0D6AE906BB3C25037E2D74CA8F3/share/5ce1ad8430e190e282cc234c79c320c49906a7e2">https://www.cambridge.org/core/journals/natural-language-engineering/article/twentyfive-years-of-information-extraction/0E5BB0D6AE906BB3C25037E2D74CA8F3/share/5ce1ad8430e190e282cc234c79c320c49906a7e2</A></kbd>

</DD>
<DT><A ID="foot137">... Quasi-Identity</A><A
 HREF="main.html#tex2html65"><SUP>31</SUP></A></DT>
<DD><kbd><A ID="tex2html66"
  HREF="https://www.aclweb.org/anthology/W13-1203/">https://www.aclweb.org/anthology/W13-1203/</A></kbd>

</DD>
<DT><A ID="foot138">... Understanding</A><A
 HREF="main.html#tex2html67"><SUP>32</SUP></A></DT>
<DD><kbd><A ID="tex2html68"
  HREF="https://www.aclweb.org/anthology/W18-5446/">https://www.aclweb.org/anthology/W18-5446/</A></kbd>

</DD>
<DT><A ID="foot139">... Objectives</A><A
 HREF="main.html#tex2html69"><SUP>33</SUP></A></DT>
<DD><kbd><A ID="tex2html70"
  HREF="https://www.aclweb.org/anthology/D19-1448/">https://www.aclweb.org/anthology/D19-1448/</A></kbd>

</DD>
<DT><A ID="foot140">... Models</A><A
 HREF="main.html#tex2html71"><SUP>34</SUP></A></DT>
<DD><kbd><A ID="tex2html72"
  HREF="https://www.aclweb.org/anthology/N16-1014/">https://www.aclweb.org/anthology/N16-1014/</A></kbd>

</DD>
<DT><A ID="foot141">... too?</A><A
 HREF="main.html#tex2html73"><SUP>35</SUP></A></DT>
<DD><kbd><A ID="tex2html74"
  HREF="https://www.aclweb.org/anthology/P18-1205/">https://www.aclweb.org/anthology/P18-1205/</A></kbd>

</DD>
<DT><A ID="foot142">... Data</A><A
 HREF="main.html#tex2html75"><SUP>36</SUP></A></DT>
<DD><kbd><A ID="tex2html76"
  HREF="https://www.aclweb.org/anthology/2020.acl-main.463/">https://www.aclweb.org/anthology/2020.acl-main.463/</A></kbd>

</DD>
<DT><A ID="foot143">... NLP</A><A
 HREF="main.html#tex2html77"><SUP>37</SUP></A></DT>
<DD><kbd><A ID="tex2html78"
  HREF="https://aclweb.org/anthology/papers/P/P19/P19-1355/">https://aclweb.org/anthology/papers/P/P19/P19-1355/</A></kbd>

</DD>
<DT><A ID="foot144">... Encoders</A><A
 HREF="main.html#tex2html79"><SUP>38</SUP></A></DT>
<DD><kbd><A ID="tex2html80"
  HREF="https://www.aclweb.org/anthology/N19-1063/">https://www.aclweb.org/anthology/N19-1063/</A></kbd>

</DD>
</DL>
<BR><HR>
<ADDRESS>
jonmay@isi.edu
</ADDRESS>
</BODY>
</HTML>
